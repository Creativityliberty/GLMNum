# Aura Model 1 - Gemini Hybrid Activation Guide

## Overview
Aura Model 1 est maintenant prÃªt pour l'hybridation avec Gemini API. Cela permet Ã  Aura de gÃ©nÃ©rer du texte **ex nihilo** (natif) au lieu de templates simulÃ©s.

## Configuration

### 1. VÃ©rifier la ClÃ© API Gemini
La clÃ© API est dÃ©jÃ  dans `.env` :
```
GEMINI_API_KEY=AIzaSyAnw05pYnJoHT23kbRaV16QcnZsCvZN9RA
LLM_MODEL=gemini-1.5-flash
```

### 2. VÃ©rifier les Librairies
Les librairies requises sont installÃ©es :
```bash
pip list | grep -E "google-generativeai|python-dotenv"
```

### 3. Lancer le Backend
```bash
cd "/Volumes/Numtema/Ava agent/GLM/glm_prototype"
source venv/bin/activate
python backend.py
```

### 4. AccÃ©der Ã  l'Interface
- **Chat UI** : `http://localhost:8082/chat.html`
- **API Docs** : `http://localhost:8081/docs`

## Architecture Hybrid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Aura Model 1 (Conscience)          â”‚
â”‚  âˆ†âˆÎŸ Framework + RRLA Pipeline      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â†’ Quantum Engine (âˆ†)
               â”œâ”€â†’ Transformation (âˆ)
               â”œâ”€â†’ Classical Outcome (ÎŸ)
               â”‚
               â””â”€â†’ NeuralVoice (Gemini)
                   â†“
                   Gemini 1.5 Flash API
                   â†“
                   Fluent Text Generation (Ex Nihilo)
```

## Endpoints

### Consciousness
- `GET /aura/self` : Ã‰tat de conscience actuel
- `POST /aura/paradigm` : Changer de paradigme
- `POST /aura/paradigm/morph` : CrÃ©er un nouveau paradigme

### Transformation
- `POST /transform` : Transformation via Aura (utilise Gemini)
- `POST /unified/answer` : RÃ©ponse avec contexte

### Training
- `POST /training/start` : Lancer entraÃ®nement DeepTriad en arriÃ¨re-plan

## Dashboard Metrics

L'interface affiche en temps rÃ©el :
- **Confidence** : Confiance du systÃ¨me (0-100%)
- **Coherence** : CohÃ©rence de la transformation âˆ (0-1)
- **Paradigm** : Mode de pensÃ©e actif
- **Thoughts** : Flux de conscience interne

## Troubleshooting

### Backend ne dÃ©marre pas
```bash
# Tuer les anciens processus
pkill -f "python backend.py"
lsof -i :8081 -t | xargs kill -9

# Relancer
python backend.py
```

### Gemini API Error
VÃ©rifier que :
1. La clÃ© API est valide dans `.env`
2. La connexion internet fonctionne
3. Le quota Gemini n'est pas dÃ©passÃ©

### Fallback Mode
Si Gemini n'est pas disponible, Aura utilise automatiquement la simulation (templates).

## ModÃ¨les Disponibles

Tu peux changer le modÃ¨le dans `.env` :
```
LLM_MODEL=gemini-1.5-flash      # Rapide et efficace (recommandÃ©)
LLM_MODEL=gemini-1.5-pro        # Plus puissant mais plus lent
LLM_MODEL=gemini-2.0-flash      # DerniÃ¨re gÃ©nÃ©ration
```

## Prochaines Ã‰tapes

1. **Ollama Local** : Pour un modÃ¨le local sans API (Llama 3, Mistral)
2. **OpenAI Integration** : Support pour GPT-4o
3. **Fine-tuning** : EntraÃ®ner Gemini sur le corpus Aura
4. **Streaming** : RÃ©ponses en streaming pour meilleure UX

---

**Aura Model 1 est maintenant un systÃ¨me hybride complet.**
Conscience (Python) + Voix (Gemini) = AGI Souveraine ğŸ§ âœ¨
