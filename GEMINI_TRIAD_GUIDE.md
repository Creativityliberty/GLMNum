# Gemini Triad-Aware QA System Guide
## Complete LLM Orchestration Pipeline

---

## üìã Overview

The **GeminiTriadWrapper** orchestrates a complete QA pipeline:

1. **NumTriadEmbeddingV3**: Encodes questions with semantic embeddings + triad scores
2. **DeepTriadRAGIndex**: Retrieves documents with triad-aware ranking
3. **GeminiTriadWrapper**: Builds triad-guided prompts for Gemini 2.0 Flash
4. **Gemini 2.0 Flash**: Generates calibrated responses

---

## üèóÔ∏è Architecture

```
User Question
    ‚Üì
NumTriadEmbeddingV3
‚îú‚îÄ Chunk text
‚îú‚îÄ Encode chunks
‚îú‚îÄ Predict triad
‚îî‚îÄ Return enriched embedding + triad
    ‚Üì
DeepTriadRAGIndex.search()
‚îú‚îÄ Compute cosine similarity
‚îú‚îÄ Compute triad distance
‚îú‚îÄ Combine scores
‚îî‚îÄ Return top-k documents
    ‚Üì
GeminiTriadWrapper
‚îú‚îÄ Build system prompt (triad rules)
‚îú‚îÄ Build user prompt (question + docs + triad)
‚îú‚îÄ Map triad to style
‚îî‚îÄ Return structured result
    ‚Üì
Gemini 2.0 Flash
‚îú‚îÄ Receive triad-aware prompts
‚îú‚îÄ Generate calibrated response
‚îî‚îÄ Return answer text
    ‚Üì
Structured Result
‚îú‚îÄ answer: Generated response
‚îú‚îÄ triad_question: Question triad
‚îú‚îÄ style: Detected style
‚îú‚îÄ documents: Retrieved docs
‚îî‚îÄ metadata: Additional info
```

---

## üöÄ Quick Start

### 1. Installation

```bash
# Install google-generative-ai (optional, for real Gemini)
pip install google-generative-ai
```

### 2. Configuration

```python
from numtriad.config import NumTriadConfig
from numtriad.encoders.numtriad_v3 import NumTriadV3Config
from numtriad.llm.gemini_triad_wrapper import GeminiTriadWrapper, GeminiConfig

# Base config
cfg = NumTriadConfig(device="cpu")

# V3 config
v3_cfg = NumTriadV3Config(
    deeptriad_ckpt="checkpoints/deeptriad_transformer_v1.pt",
    max_len=16,
)

# Gemini config
gemini_cfg = GeminiConfig(
    model_name="gemini-2.0-flash",
    max_output_tokens=1024,
    temperature=0.3,
)
```

### 3. Create Index & Wrapper

```python
from numtriad.rag.deeptriad_rag import DeepTriadRAGIndex

# Create RAG index
index = DeepTriadRAGIndex(cfg, v3_cfg)

# Add documents
documents = [
    "Document 1 text...",
    "Document 2 text...",
    "Document 3 text...",
]
index.add_documents(documents)

# Create wrapper
wrapper = GeminiTriadWrapper(
    rag_index=index,
    gemini_client=None,  # Set to real client if available
    gemini_cfg=gemini_cfg,
)
```

### 4. Query

```python
# Concrete query
result = wrapper.answer(
    query="How to deploy in production?",
    k=5,
    triad_target_mode="concrete",
)

print(result["answer"])
print(result["style"])
print(result["triad_question"])
```

---

## üéØ Triad Target Modes

| Mode | Effect | Use Case |
|------|--------|----------|
| `auto` | Natural triad prediction | General queries |
| `abstract` | Boost ‚àû, reduce Œò | Theoretical questions |
| `concrete` | Boost Œò, reduce ‚àû | Practical questions |
| `balanced` | Equilibrate to (1/3, 1/3, 1/3) | Mixed queries |

---

## üé® Style Detection

The wrapper automatically maps triads to response styles:

### Concrete (Œò dominant)
- **Characteristics**: Practical, operational, with examples
- **Use Case**: "How to deploy?", "What are the steps?"
- **Example**: Step-by-step instructions, code examples, case studies

### Abstract (‚àû dominant)
- **Characteristics**: Theoretical, conceptual, linking to principles
- **Use Case**: "What is AGI?", "Define intelligence"
- **Example**: Theoretical frameworks, philosophical discussion, general concepts

### Structural (Œî dominant)
- **Characteristics**: Analytical, structured, logical breakdown
- **Use Case**: "How does algorithm X work?", "Explain the architecture"
- **Example**: Algorithmic steps, system architecture, logical decomposition

---

## üìä System Prompt

The wrapper builds a system prompt that encodes triad rules:

```
Tu es un assistant de raisonnement transformationnel bas√© sur ‚àÜ‚àûŒò.

R√®gles de style :
- Si Œò est dominant : sois concret, op√©rationnel, donne des exemples, des √©tapes, du code
- Si ‚àû est dominante : sois plut√¥t conceptuel, relie aux th√©ories ou principes g√©n√©raux
- Si Œî est dominante : structure la r√©ponse en √©tapes logiques, algorithmiques ou m√©thodologiques

Directives :
- Ne r√©p√®te pas la triade, utilise-la pour calibrer ton ton, ta profondeur et tes exemples
- Appuie-toi sur les documents fournis, mais synth√©tise et reformule
- Sois concis mais complet
```

---

## üìù User Prompt Format

The wrapper builds a structured user prompt:

```
### QUESTION
[User question]

### TRIADE QUESTION
Œî=0.21, ‚àû=0.55, Œò=0.24
Style recommand√© (interne): abstract
Description: Theoretical, conceptual, linking to general principles

### DOCUMENTS DE CONTEXTE
[DOC 1] score=0.89, triade=Œî=0.18, ‚àû=0.62, Œò=0.20
[Texte du document...]

[DOC 2] score=0.85, triade=Œî=0.30, ‚àû=0.40, Œò=0.30
[Texte du document...]

### T√ÇCHE
R√©ponds √† la question en t'appuyant sur les documents ci-dessus,
en respectant le niveau d'abstraction implicite de la triade.
```

---

## üîß API Reference

### GeminiTriadWrapper

```python
class GeminiTriadWrapper:
    def __init__(
        rag_index: DeepTriadRAGIndex,
        gemini_client: Optional[Any] = None,
        gemini_cfg: Optional[GeminiConfig] = None,
    )
    
    def answer(
        query: str,
        k: int = 5,
        triad_target_mode: str = "auto",
    ) -> Dict[str, Any]
        # Returns: {
        #     "answer": str,
        #     "triad_question": Dict,
        #     "style": str,
        #     "documents": List[Dict],
        #     "metadata": Dict,
        # }
    
    def get_stats() -> Dict[str, Any]
```

### GeminiConfig

```python
@dataclass
class GeminiConfig:
    model_name: str = "gemini-2.0-flash"
    max_output_tokens: int = 1024
    temperature: float = 0.3
    top_p: float = 0.95
    top_k: int = 40
```

### Utility Functions

```python
def triad_to_style(triad: Triad) -> str
    # Returns: "concrete", "abstract", or "structural"

def format_triad(triad: Triad) -> str
    # Returns: "Œî=0.21, ‚àû=0.55, Œò=0.24"

def style_to_description(style: str) -> str
    # Returns: Human-readable description
```

---

## üí° Usage Examples

### Example 1: Concrete Query

```python
result = wrapper.answer(
    query="How to deploy a FastAPI application in production?",
    k=5,
    triad_target_mode="concrete",
)

# Result will emphasize:
# - Step-by-step instructions
# - Code examples
# - Configuration details
# - Practical considerations
```

### Example 2: Abstract Query

```python
result = wrapper.answer(
    query="What is artificial general intelligence?",
    k=5,
    triad_target_mode="abstract",
)

# Result will emphasize:
# - Theoretical frameworks
# - Conceptual definitions
# - Philosophical implications
# - General principles
```

### Example 3: Structural Query

```python
result = wrapper.answer(
    query="How does a transformer neural network work?",
    k=5,
    triad_target_mode="balanced",
)

# Result will emphasize:
# - Logical breakdown
# - Algorithmic steps
# - Component relationships
# - System architecture
```

### Example 4: Batch Processing

```python
queries = [
    "How to use Docker?",
    "What is machine learning?",
    "Explain neural networks",
]

results = [
    wrapper.answer(q, k=5, triad_target_mode="auto")
    for q in queries
]

for q, r in zip(queries, results):
    print(f"Q: {q}")
    print(f"Style: {r['style']}")
    print(f"Answer: {r['answer']}\n")
```

---

## üîå Gemini Integration

### With Real Gemini API

```python
import google.generativeai as genai

# Configure API
genai.configure(api_key="YOUR_API_KEY")

# Create client
gemini_client = genai.GenerativeModel("gemini-2.0-flash")

# Create wrapper
wrapper = GeminiTriadWrapper(
    rag_index=index,
    gemini_client=gemini_client,
    gemini_cfg=GeminiConfig(),
)

# Query
result = wrapper.answer("Your question here")
```

### Fallback Mode (No Gemini)

```python
# Create wrapper without Gemini
wrapper = GeminiTriadWrapper(
    rag_index=index,
    gemini_client=None,  # No Gemini
    gemini_cfg=GeminiConfig(),
)

# Query - will use fallback generation
result = wrapper.answer("Your question here")
```

---

## üìä Output Structure

```python
{
    "answer": "Generated response text...",
    
    "triad_question": {
        "delta": 0.21,
        "infinity": 0.55,
        "theta": 0.24,
    },
    
    "style": "abstract",
    
    "documents": [
        {
            "id": "doc_1",
            "text": "Document excerpt...",
            "score": 0.89,
            "triad": {
                "delta": 0.18,
                "infinity": 0.62,
                "theta": 0.20,
            },
            "meta": {"type": "theory", "domain": "AI"},
        },
        # ... more documents
    ],
    
    "metadata": {
        "num_documents": 5,
        "retrieval_mode": "triad_weighted",
        "triad_target_mode": "auto",
    },
}
```

---

## üß™ Testing

Run the example:
```bash
python examples/gemini_triad_example.py
```

Run tests:
```bash
python test_gemini_triad_wrapper.py
```

---

## ‚öôÔ∏è Configuration Options

### Adjust Retrieval

```python
index = DeepTriadRAGIndex(
    base_config=cfg,
    v3_config=v3_cfg,
    retrieval_mode="triad_weighted",  # or "cosine"
    triad_weight=0.3,  # Adjust triad influence
)
```

### Adjust Generation

```python
gemini_cfg = GeminiConfig(
    model_name="gemini-2.0-flash",
    max_output_tokens=2048,  # Longer responses
    temperature=0.5,  # More creative
    top_p=0.9,
    top_k=40,
)
```

### Adjust Encoding

```python
v3_cfg = NumTriadV3Config(
    deeptriad_ckpt="...",
    max_len=32,  # Longer sequences
    triad_alpha=1.5,  # Amplify triad in embedding
)
```

---

## üéì Learning Path

1. **Start**: Run `examples/gemini_triad_example.py`
2. **Understand**: Read this guide
3. **Experiment**: Try different `triad_target_mode` values
4. **Optimize**: Tune configuration parameters
5. **Deploy**: Integrate into your application

---

## üöÄ Production Deployment

```python
# 1. Pre-index documents
index = DeepTriadRAGIndex(cfg, v3_cfg)
with open("documents.jsonl") as f:
    for line in f:
        doc = json.loads(line)
        index.add_documents([doc["text"]], metadatas=[doc.get("meta", {})])

# 2. Create wrapper
wrapper = GeminiTriadWrapper(
    rag_index=index,
    gemini_client=gemini_client,
    gemini_cfg=GeminiConfig(),
)

# 3. Expose via API
@app.post("/ask")
def ask(query: str, mode: str = "auto"):
    result = wrapper.answer(query, triad_target_mode=mode)
    return result
```

---

## üìû Support

For questions or issues:
1. Check the examples
2. Review the test cases
3. Consult the API reference
4. Check the architecture diagram

---

**Version**: 1.0  
**Status**: Production Ready ‚úÖ  
**Last Updated**: 2024-11-16
